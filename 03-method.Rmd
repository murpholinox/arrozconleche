# Limpieza de datos
Habiendo verificado la naturaleza de nuestros datos, sigue el turno de su limpieza que consiste en aplicar los siguientes filtros:

1. Elimina entradas con una resolución peor que 2 Å. 
2. Elimina entradas donde no se anotó el pH en su respectiva columna. Según la [página](http://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v50.dic/Categories/exptl_crystal_grow.html) del diccionario `.mmcif` dicha anotación se encuentra en 83.7 % del total de entradas depositadas en el PDB.
3. Elimina entradas donde el número de entidades sea mayor o igual a dos.
4. Elimina entradas donde la cadena polipeptídica tenga mutaciones o traiga el péptido señal o la cola de histidinas o donde no se haya modelado el último aminoácido (esto siempre y cuando la secuencia consenso en el PDB sea la secuencia wt).

>Nota: Lo último es desafortunado; sin embargo, la alternativa es mucho más costosa en tiempo/trabajo y número de entradas perdidas. La alternativa: Bajar la densidad electrónica, el modelo y obtener el coeficiente de correlación entre ambos a nivel local (por aminoácido), si este coeficiente no es mayor que algún valor, podríamos eliminar estas entradas. Desventajas: (1) No todos los modelos tienen los datos depositados en el PDB, por lo tanto no será posible recrear la densidad electrónica. Esto no significa que su cristal de proteína a cierto pH no haya existido. (2) El coeficiente de correlación depende de varios factores, en casos difíciles esto se tendría que hacer a ojo, entrada por entrada, y sería altamente dependiente de la persona que lo realice (yo). 

## Filtros 1 y 2

```{r, warning=FALSE, message=FALSE}
# Filtro 0
fil0 <-df2 %>%
  filter(!ide =="") # Si no tiene identificador se va.
# Filtro 1
fil1 <- fil0 %>%
  filter(rs1 <= 2.0) # Mala resolución no me sirve.
# Filtro 2
fil2 <-fil1 %>%
  filter(!is.na(peh)) # Si no tiene pH se va.
write_excel_csv(fil2, "/run/media/murphy/lolita/doctorado/clean/fil2.csv")
# wc -l fil2.csv 
# 69669 fil2.csv
```

## Filtro 3
```{bash}
cd /run/media/murphy/lolita/doctorado/clean
awk -F "," '{print $1}' fil2.csv | tail -n +2 | uniq -c | sort -n > a
# wc -l a 
# 58388 a
# `a`: dos columnas, la primera es el número de entidades y la segunda es el pdb id.
awk '{if($1>=2) print $2;}' a > pat
grep -v -f pat fil2.csv > fil3.csv
# wc -l fil3.csv 
#49746 fil3.csv
```

```{r, warning=FALSE, message=FALSE}
# Carga fil3.
fil3 <- read_csv("/run/media/murphy/lolita/doctorado/clean/fil3.csv")
```


## Filtro 4
Saca el ide, de acuerdo al *top* 50. 
### Top50
Cuenta la frecuencia del identificador de UniProt, con base en esto realiza una lista ordenada en orden descendente.

> Nota: Digo identificador de UniProt, porque esta es la base de datos que el PDB liga con mayor frecuencia a sus entradas, pero en general puede ser el identificador de cualquier otra base de datos, incluso el mismo PDB.

```{r}
fil3cola <- fil3 %>%
  count(ide, name="cta_ide") %>% # Colapsa los datos hacia n
  arrange(desc(cta_ide))
# f3_nocola <- fil3 %>% # Agrega n
#   add_count(ide, name="cta_ide") %>%
#   arrange(desc(cta_ide)) # Útil si se necesita  una gráfica ordenada por cta_ide.
# Una tabla
tab_fil3cola<-head(fil3cola, n=50) #Aquí escoge n.
kable(tab_fil3cola) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=F)
write_excel_csv(tab_fil3cola, "/run/media/murphy/lolita/doctorado/clean/tab_fil3cola.csv")
```

```{r}
ide_in_tf3c <- tab_fil3cola$ide
for (j in seq(1,50))
{
ide_i_ <-ide_in_tf3c[[j]]
filename <- paste("/run/media/murphy/lolita/doctorado/clean/fil4/dir/", ide_i_, sep="") # 
write_excel_csv(filter(fil3, ide==ide_i_), filename)
}
```

```{bash}
cd /run/media/murphy/lolita/doctorado/clean/fil4/dir 
for k in `ls -1rt` # Ordenados
do
awk -F "," '{print $1}' "$k" | tail -n +2 | tr '[:upper:]' '[:lower:]' > pdbs_"$k"
sed 's/$/.cif.gz/'g pdbs_"$k" > list_pdbs_id_"$k"
mkdir sub_"$k"
cat list_pdbs_id_"$k" | while read line; do cp /run/media/murphy/lolita/doctorado/PDB_backup/$line /run/media/murphy/lolita/doctorado/clean/fil4/dir/sub_"$k" ; done 
/home/murphy/Repos/gemmi/gemmi grep --delimiter='¿' _entity_poly.entity_id -a _entity_poly.type -a _entity_poly.pdbx_seq_one_letter_code_can sub_"$k"/  > can_seq_"$k".csv
awk -F "¿" '{print ">"$1"\n"$4}' can_seq_"$k".csv | sed 's/\\n//g' > seqs_"$k".fa
#awk -F "¿" '{print $1"\t"$4}' can_seq_"$k".csv | sed 's/\\n//g' > seqsforr_"$k".fa
# mafft mejor que muscle y clustal omega
mafft --anysymbol --quiet --op 15 --ep 15 --addfragments seqs_"$k".fa /run/media/murphy/lolita/doctorado/clean/fil4/ori_seq/ori_"$k".fa > msa_"$k".afa
cons msa_"$k".afa -outseq cons_"$k" -identity 1 -datafile EBLOSUM62 -sprotein1
# Checar la secuencia consenso en Ugene con el alineamiento. 
# Esto tarda 4 minutos!
grep -v EMBOSS cons_"$k" | sed 's/x//g' | tr '\n' ' ' | sed 's/ //g' > cons_"$k"_c
done
```

## El último cacho
```{r, warning=FALSE, message=FALSE}
library(stringdist)
for (j in seq(1,50))
{
  ide <-ide_in_tf3c[[j]] # identificador
  file1 <- paste("/run/media/murphy/lolita/doctorado/clean/fil4/dir/can_seq_", ide, ".csv", sep="")
  impo1 <- read_delim(file1,  # carga el archivo con las secuencias
    "¿", escape_double = FALSE, col_names = FALSE, 
    comment = "*>", trim_ws = TRUE)
  pdb<-impo1$X1
  nde<-stringr::str_replace(impo1$X2, '�', '')
  tde<-stringr::str_replace(impo1$X3, '�', '')
  sec0<-stringr::str_replace(impo1$X4, '�', '')
  sec<-stringr::str_replace_all(sec0, '\\\\n', '')
  oname1 = paste("df", "_", ide, sep="")
  assign(oname1, data.frame(pdb, nde, tde, sec)) # Usa assign
  file2 <- paste("/run/media/murphy/lolita/doctorado/clean/fil4/dir/cons_", ide, "_c", sep="")
  impo2 <- read_csv(file2, col_names = FALSE)
  oname2 = paste("cons_", ide, sep="")
  assign(oname2, impo2$X1) # de nuevo.
# n<-nrow(oname1)
#   for (i in seq(1,n))
#   {
#     y<-adist(oname1$sec[i], oname2)
#     print(y)
# }
}
```

## Obtiene nombres
Por simplicidad trabaja con nombres.

```{bash, eval=FALSE}
cd /run/media/murphy/lolita/doctorado/clean
# Obtiene los identificadores
awk -F "," '{print $1}'  tabla_f3_cola.csv | tail -n +2 > top50_uac.lst
# Convierte de lista a línea.
tr '\n' ' ' < top50_uac.lst > top50_uac.ln
# Descarga el programa.
wget -O get_info.pl https://raw.githubusercontent.com/murpholinox/usefulscripts/master/uniprot_batch_retrieval.pl
# Instala requisitos para correr el programa.
# sudo dnf install 'perl(LWP::UserAgent)' 
# sudo dnf install perl-LWP-Protocol-https
chmod u+x get_info.pl
# Corre el programa.
perl ./get_info.pl top50_uac.ln > top50_wholeinfo.txt
# Obtiene identificadores.
egrep "^ID|^AC|^DE   RecN|^OS" top50_wholeinfo.txt > top50_ids_acs_fnames_org.txt
# Obtiene nombres.
grep "^DE" top50_ids_acs_fnames_org.txt | awk -F "=" '{print $2}' | sed 's/Full=//'g | sed 's/;$/,/g' > top50_fnames.lst
# Checa nombres con comas
awk -F , 'NF != 2 ' < top50_fnames.lst
# HLA class I histocompatibility antigen, A alpha chain,
#Nitric oxide synthase, brain,
#DNA polymerase I, thermostable,
#Glycogen phosphorylase, muscle form,
# Elimina comas
sed -e 's/antigen, A alpha/antigen A alpha/g ; s/synthase, brain,/synthase brain,/g ; s/polymerase I, thermostable,/polymerase I thermostable,/g ; s/phosphorylase, muscle form,/phosphorylase muscle form,/g' top50_fnames.lst > top50_fnames_fx.lst
# Obtiene organismos. 
# Elimina organismos con doble línea OS
grep -v "^OS   (HIV-1)"  top50_ids_acs_fnames_org.txt > b
grep -v "^OS   10044" b > top50_ids_acs_fnames_org_fx.txt
grep "^OS" top50_ids_acs_fnames_org_fx.txt | sed 's/^OS   //'g > top50_org.txt
# Pega los nombres de las proteínas con su AC, `SUMA` y organismo.
paste top50_fnames_fx.lst top50_uac.lst > c
paste -d, c top50_org.txt > top50_final.csv
```

Con `top50_final.csv` podemos construir una tabla para la presentación. 

## TODO
Falta checar el intervalo de pH de las 50 proteínas más representadas y checar las respectivas gráficas de pH

```{r, eval=FALSE}
ggplot(filter(clean, UAC=="P00698"), aes(x=Length)) + geom_bar() + facet_wrap( ~ sg) + xlab("Residuos de aminoácido") + ylab ("Número de estructuras")
ggsave("P00698_bar-length_wrap-sg.pdf", width = 20, units = "cm") 
ggsave("P00698_bar-length_wrap-sg.png", width = 20, units = "cm") 
ggplot(filter(clean, UAC=="P00698" & sg=="P 43 21 2"), aes(x=pH)) + geom_bar() + xlab("pH") + ylab ("Número de estructuras")
ggsave("P00698_ph-sg_P_43_21_2.pdf", width = 20, units = "cm") 
ggsave("p00698_ph-sg_P_43_21_2.png", width = 20, units = "cm") 
```

