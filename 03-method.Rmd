# Limpieza de datos
Habiendo verificado la naturaleza de nuestros datos, sigue el turno de su limpieza que consiste en aplicar los siguientes filtros:

1. Elimina entradas con una resolución peor que 2 Å. 
2. Elimina entradas donde no se anotó el pH en su respectiva columna. Según la [página](http://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v50.dic/Categories/exptl_crystal_grow.html) del diccionario `.mmcif` dicha anotación se encuentra en 83.7 % del total de entradas depositadas en el PDB.
3. Elimina entradas donde el número de entidades sea mayor o igual a dos.
4. Elimina entradas donde la cadena polipeptídica tenga mutaciones o traiga el péptido señal o la cola de histidinas o donde no se haya modelado el último aminoácido (esto siempre y cuando la secuencia consenso en el PDB sea la secuencia wt).

>Nota: Lo último es desafortunado; sin embargo, la alternativa es mucho más costosa en tiempo/trabajo y número de entradas perdidas. La alternativa: Bajar la densidad electrónica, el modelo y obtener el coeficiente de correlación entre ambos a nivel local (por aminoácido), si este coeficiente no es mayor que algún valor, podríamos eliminar estas entradas. Desventajas: (1) No todos los modelos tienen los datos depositados en el PDB, por lo tanto no será posible recrear la densidad electrónica. Esto no significa que su cristal de proteína a cierto pH no haya existido. (2) El coeficiente de correlación depende de varios factores, en casos difíciles esto se tendría que hacer a ojo, entrada por entrada, y sería altamente dependiente de la persona que lo realice (yo). 

## Filtros 1 y 2

```{r, warning=FALSE, message=FALSE}
# Filtro 0
fil0 <-df2 %>%
  filter(!ide =="") # Si no tiene identificador se va.
# Filtro 1
fil1 <- fil0 %>%
  filter(rs1 <= 2.0) # Mala resolución no me sirve.
# Filtro 2
fil2 <-fil1 %>%
  filter(!is.na(peh)) # Si no tiene pH se va.
write_excel_csv(fil2, "/run/media/murphy/lolita/doctorado/clean/fil2.csv")
#wc -l fil2.csv 
#69669 fil2.csv
```

## Filtro 3
```{bash}
cd /run/media/murphy/lolita/doctorado/clean
awk -F "," '{print $1}' fil2.csv | tail -n +2 | uniq -c | sort -n > a
#wc -l a 
#58388 a
# a contiene dos columnas, la primera es el número de entidades y la segunda es el pdb id.
awk '{if($1>=2) print $2;}' a > pat
grep -v -f pat fil2.csv > fil3.csv
```

```{r, warning=FALSE, message=FALSE}
# Carga fil3.
fil3 <- read_csv("/run/media/murphy/lolita/doctorado/clean/fil3.csv")
```


## Filtro 4
Saca el ide, de acuerdo al top50. 
### Top50
Cuenta la frecuencia del identificador de UniProt, con base en esto realiza una lista ordenada en orden descendente.

> Nota: Digo identificador de UniProt, porque esta es la base de datos que el PDB liga con mayor frecuencia a sus entradas, pero en general puede ser el identificador de cualquier otra base de datos.

```{r}
fil3cola <- fil3 %>%
  count(ide, name="cta_ide") %>% # Colapsa los datos hacia n
  arrange(desc(cta_ide))
#f3_nocola <- fil3 %>% # Agrega n
#  add_count(ide, name="cta_ide") %>%
#  arrange(desc(cta_ide)) # TODO: No necesario a menos que se necesite una gráfica ordenada por cta_ide.
# Una tabla
tab_fil3cola<-head(fil3cola, n=50) #Aquí escoge n.
kable(tab_fil3cola) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width=F)
write_excel_csv(tab_fil3cola, "/run/media/murphy/lolita/doctorado/clean/tab_fil3cola.csv")
```

```{r}
ide_in_tf3c <- tab_fil3cola$ide
for (j in seq(1,50))
{
ide_i_ <-ide_in_tf3c[[j]]
filename <- paste("/run/media/murphy/lolita/doctorado/clean/fil4/dir/", ide_i_, sep="") # 
write_excel_csv(filter(fil3, ide==ide_i_), filename)
}
```

```{bash}
cd /run/media/murphy/lolita/doctorado/clean/fil4/dir # Tiene que estar vacío
for k in `ls -1 *`
do
awk -F "," '{print $1}' "$k" | tail -n +2 | tr '[:upper:]' '[:lower:]' > pdbs_"$k"
sed 's/$/.cif.gz/'g pdbs_"$k" > list_pdbs_id_"$k"
rm -rf sub_"$k"/
mkdir sub_"$k"
cat list_pdbs_id_"$k" | while read line; do cp /run/media/murphy/lolita/doctorado/PDB_backup/$line /run/media/murphy/lolita/doctorado/clean/fil4/dir/sub_"$k" ; done 
gemmi grep --delimiter='¿' _entity_poly.entity_id -a _entity_poly.type -a _entity_poly.pdbx_seq_one_letter_code_can sub_"$k"/  > can_seq_"$k".csv 
awk -F "¿" '{print ">"$1"\n"$4}' can_seq_"$k".csv | sed 's/\\n//g' > seqs_"$k".fa
cat /run/media/murphy/lolita/doctorado/clean/fil4/ori_seq/ori_"$k".fa >> /run/media/murphy/lolita/doctorado/clean/fil4/dir/seqs_"$k".fa
clustalo -i seqs_"$k".fa -o clu_"$k".afa # Checar en Ugene,
muscle -in seqs_"$k".fa -out mus_"$k".afa
cons clu_"$k".afa -outseq cons_"$k" -identity 1 -datafile EBLOSUM62 -sprotein1
# Checar la secuencia consenso en Ugene con el alineamiento. 
# Esto tarda 4 minutos!
done
```


## El último cacho
```{r, warning=FALSE, message=FALSE}
for (j in seq(1,50))
{
ide_i_ <-ide_in_tf3c[[j]]
filename <- paste("/run/media/murphy/lolita/doctorado/prueba/can_seq_", ide_i_, ".csv", sep="")
ide_i_ <-read_delim(filename, 
    "¿", escape_double = FALSE, col_names = FALSE, 
    comment = "*>", trim_ws = TRUE)
pdb<-ide_i_$X1
nde<-stringr::str_replace(ide_i_$X2, '�', '')
tde<-stringr::str_replace(ide_i_$X3, '�', '')
sec0<-stringr::str_replace(ide_i_$X4, '�', '')
sec<-stringr::str_replace_all(sec0, '\\\\n', '')
# TODO: EL problema es la secuencia WT original, no siempre es la más representada en el PDB.
# Necesitamos un diccionario con el ide y la secuencias más representada en el PDB de ese ide.
ulti<-length(sec) 
repe <- seq(1,ulti)
lop<-c()
bad_seq<-c()
sec_original<-c("KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL")
for (i in repe) {
long_i<-str_length(sec[[i]])
lop<-c(lop,long_i)
if(sec[[i]] != sec_original){
bad_seq<-c(bad_seq, "NotWt")
} else {
  bad_seq<-c(bad_seq,"Wt")
}
}
ldp<-as.data.frame(lop)
ide_i_<-data.frame(pdb, nde, tde, sec, ldp, bad_seq)
}
```

## Obtiene nombres
Por simplicidad trabaja con nombres.

```{bash, eval=FALSE}
cd /run/media/murphy/lolita/doctorado/clean
# Obtiene los identificadores
awk -F "," '{print $1}'  tabla_f3_cola.csv | tail -n +2 > top50_uac.lst
# Convierte de lista a línea.
tr '\n' ' ' < top50_uac.lst > top50_uac.ln
# Descarga el programa.
wget -O get_info.pl https://raw.githubusercontent.com/murpholinox/usefulscripts/master/uniprot_batch_retrieval.pl
# Instala requisitos para correr el programa.
# sudo dnf install 'perl(LWP::UserAgent)' 
# sudo dnf install perl-LWP-Protocol-https
chmod u+x get_info.pl
# Corre el programa.
perl ./get_info.pl top50_uac.ln > top50_wholeinfo.txt
# Obtiene identificadores.
egrep "^ID|^AC|^DE   RecN|^OS" top50_wholeinfo.txt > top50_ids_acs_fnames_org.txt
# Obtiene nombres.
grep "^DE" top50_ids_acs_fnames_org.txt | awk -F "=" '{print $2}' | sed 's/Full=//'g | sed 's/;$/,/g' > top50_fnames.lst
# Checa nombres con comas
awk -F , 'NF != 2 ' < top50_fnames.lst
# HLA class I histocompatibility antigen, A alpha chain,
#Nitric oxide synthase, brain,
#DNA polymerase I, thermostable,
#Glycogen phosphorylase, muscle form,
# Elimina comas
sed -e 's/antigen, A alpha/antigen A alpha/g ; s/synthase, brain,/synthase brain,/g ; s/polymerase I, thermostable,/polymerase I thermostable,/g ; s/phosphorylase, muscle form,/phosphorylase muscle form,/g' top50_fnames.lst > top50_fnames_fx.lst
# Obtiene organismos. 
# Elimina organismos con doble línea OS
grep -v "^OS   (HIV-1)"  top50_ids_acs_fnames_org.txt > b
grep -v "^OS   10044" b > top50_ids_acs_fnames_org_fx.txt
grep "^OS" top50_ids_acs_fnames_org_fx.txt | sed 's/^OS   //'g > top50_org.txt
# Pega los nombres de las proteínas con su AC, `SUMA` y organismo.
paste top50_fnames_fx.lst top50_uac.lst > c
paste -d, c top50_org.txt > top50_final.csv
```

Con `top50_final.csv` podemos construir una tabla para la presentación. 

## TODO
Falta checar el intervalo de pH de las 50 proteínas más representadas y checar las respectivas gráficas de pH

```{r, eval=FALSE}
ggplot(filter(clean, UAC=="P00698"), aes(x=Length)) + geom_bar() + facet_wrap( ~ sg) + xlab("Residuos de aminoácido") + ylab ("Número de estructuras")
ggsave("P00698_bar-length_wrap-sg.pdf", width = 20, units = "cm") 
ggsave("P00698_bar-length_wrap-sg.png", width = 20, units = "cm") 
ggplot(filter(clean, UAC=="P00698" & sg=="P 43 21 2"), aes(x=pH)) + geom_bar() + xlab("pH") + ylab ("Número de estructuras")
ggsave("P00698_ph-sg_P_43_21_2.pdf", width = 20, units = "cm") 
ggsave("p00698_ph-sg_P_43_21_2.png", width = 20, units = "cm") 
```

